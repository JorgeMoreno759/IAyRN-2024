{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6L25dXXxmDd",
        "outputId": "3172c49d-5dea-4e1f-ec38-57e1bf769357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 57s 59ms/step - loss: 0.1898 - accuracy: 0.9416\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 53s 56ms/step - loss: 0.0528 - accuracy: 0.9840\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0372 - accuracy: 0.9886\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 52s 56ms/step - loss: 0.0301 - accuracy: 0.9905\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0237 - accuracy: 0.9930\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0302 - accuracy: 0.9900\n",
            "Accuracy on test data: 0.9900000095367432\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Predicted: 7 Actual: 7\n",
            "Predicted: 2 Actual: 2\n",
            "Predicted: 1 Actual: 1\n",
            "Predicted: 0 Actual: 0\n",
            "Predicted: 4 Actual: 4\n"
          ]
        }
      ],
      "source": [
        "# Título: Entrenamiento de una Red Neuronal Convolucional para MNIST\n",
        "# Nombre: [Jorge Fabián Moreno Sarmiento]\n",
        "# Matrícula: [2015221]\n",
        "# Hora de clase: [N1]\n",
        "\n",
        "# 1. Cargar librerías\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# 2. Cargar datos\n",
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "# 3. Preprocesamiento de datos\n",
        "train_data = train_data.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_data = test_data.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# 4. Selección y entrenamiento del modelo\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# 5. Prueba de modelo\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print('Accuracy on test data:', test_acc)\n",
        "\n",
        "# 6. Predicciones\n",
        "predictions = model.predict(test_data[:5])\n",
        "for i in range(5):\n",
        "    print('Predicted:', tf.argmax(predictions[i]).numpy(), 'Actual:', tf.argmax(test_labels[i]).numpy())\n"
      ]
    }
  ]
}